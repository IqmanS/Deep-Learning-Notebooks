{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<img src=\"https://cdn.discordapp.com/attachments/1111599839663370271/1123589551244460072/CatsVsDogs.jpg\">\n\n# **Transfer Learning & Fine Tuning on MobileNetV2**","metadata":{}},{"cell_type":"markdown","source":"---\n\n# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport tensorflow as tf\nimport datetime\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nplt.style.use('dark_background')\nfrom tqdm import tqdm_notebook","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.test.is_built_with_cuda()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.test.is_gpu_available()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n# Defining Classes & Generators","metadata":{}},{"cell_type":"code","source":"classes = ['cats','dogs']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255.0, \n                               shear_range=0.15, \n                               zoom_range=0.2, \n                               horizontal_flip=True) \n\ntrain_data = generator.flow_from_directory( directory='../input/cat-and-dog/training_set/training_set', \n                                            target_size=(128, 128),\n#                                             color_mode='grayscale',\n                                            classes=classes, \n                                            batch_size=128)\n\n\ntest_data = generator.flow_from_directory( directory='../input/cat-and-dog/test_set/test_set', \n                                           target_size=(128, 128), \n#                                            color_mode='grayscale',\n                                           classes=classes, \n                                           batch_size=128,\n                                           shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n# MobileNetV2\n\n### Loading the Model","metadata":{}},{"cell_type":"code","source":"base_model = tf.keras.applications.MobileNetV2(input_shape=(128,128,3),include_top=False,weights=\"imagenet\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.summary()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Freezing the Model","metadata":{}},{"cell_type":"code","source":"base_model.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Defining the Custom Head for network","metadata":{}},{"cell_type":"code","source":"base_model.output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 2 Apporaches can be taken\n1. Using Flattening Layer\n2. Using GlobalAveragePooling Layer","metadata":{}},{"cell_type":"code","source":"global_average_layer = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\nglobal_average_layer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_layer = tf.keras.layers.Dense(units=2,activation=\"sigmoid\")(global_average_layer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.Model(inputs=base_model.input, outputs=pred_layer)\nmodel.summary()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Compiling the model","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.01),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training the model","metadata":{}},{"cell_type":"code","source":"earlyStopping =  tf.keras.callbacks.EarlyStopping(patience=3, monitor='val_accuracy',restore_best_weights=True,start_from_epoch=2)\n\n# history = model.fit_generator(train_data, epochs=5, validation_data=test_data,callbacks=[earlyStopping])\nhistory = model.fit(train_data, epochs=10, validation_data=test_data, shuffle=True, callbacks=[earlyStopping],batch_size=64)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(history.history)\ndf_loss = df[['loss', 'val_loss']]\ndf_acc =  df[['accuracy', 'val_accuracy']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplot(1,2,figsize=(10,4))\nplt.title(\"Loss & Val Loss\")\nsns.lineplot(df_loss,palette=\"flare\");\n\nplt.title(1,2,\"Accuracy & Val Accuracy\")\nplt.figure(figsize=(10,4))\nsns.lineplot(df_acc,palette=\"flare\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Fine-Tuning Base Model\n\n- DO NOT use Fine tuning on the whole network; only a few top layers are enough. In most cases, they are more specialized. The goal of the Fine-tuning is to adopt that specific part of the network for our custom (new) dataset.\n- Start with the fine tunning AFTER you have finished with transfer learning step. If we try to perform Fine tuning immediately, gradients will be much different between our custom head layer and a few unfrozen layers from the base model. ","metadata":{}}]}